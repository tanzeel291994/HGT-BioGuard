{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe8550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanzeel.shaikh/Library/Caches/pypoetry/virtualenvs/gnn-qksje4Fo-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import IMDB\n",
    "from torch_geometric.nn import HGTConv\n",
    "from torch_geometric.transforms import ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e345a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  movie={\n",
      "    x=[4278, 3066],\n",
      "    y=[4278],\n",
      "    train_mask=[4278],\n",
      "    val_mask=[4278],\n",
      "    test_mask=[4278],\n",
      "  },\n",
      "  director={ x=[2081, 3066] },\n",
      "  actor={ x=[5257, 3066] },\n",
      "  (movie, to, director)={ edge_index=[2, 4278] },\n",
      "  (movie, to, actor)={ edge_index=[2, 12828] },\n",
      "  (director, to, movie)={ edge_index=[2, 4278] },\n",
      "  (actor, to, movie)={ edge_index=[2, 12828] },\n",
      "  (director, rev_to, movie)={ edge_index=[2, 4278] },\n",
      "  (actor, rev_to, movie)={ edge_index=[2, 12828] },\n",
      "  (movie, rev_to, director)={ edge_index=[2, 4278] },\n",
      "  (movie, rev_to, actor)={ edge_index=[2, 12828] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1) Load dataset\n",
    "dataset = IMDB(root='data/IMDB', transform=ToUndirected())\n",
    "data = dataset[0]  # HeteroData\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20617011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.hetero_data.HeteroData'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca47e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['movie', 'actor']:\n",
    "    x = data[t].x\n",
    "    data[t].x = x / x.norm(p=2, dim=1, keepdim=True).clamp_min(1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef5bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for etype in list(data.edge_types):\n",
    "    if etype[1] == 'rev_to':\n",
    "        del data[etype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebc5b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['movie', 'director', 'actor'],\n",
       " [('movie', 'to', 'director'),\n",
       "  ('movie', 'to', 'actor'),\n",
       "  ('director', 'to', 'movie'),\n",
       "  ('actor', 'to', 'movie')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = data.metadata()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790145b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data node types: 'movie', 'actor', 'director'\n",
    "# labels exist on movie nodes: data['movie'].y (3 classes)\n",
    "# masks: data['movie'].train_mask / val_mask / test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8be7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 128\n",
    "\n",
    "x_dict = {}\n",
    "proj = nn.ModuleDict()\n",
    "embeddings = nn.ModuleDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727db108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12828])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict['movie', 'to', 'actor'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cc57ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 4277, 4277, 4277],\n",
       "        [ 674, 2394, 5129,  ...,  100, 1078, 1439]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict['movie', 'to', 'actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514f1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mask torch.Size([4278]) torch.bool 400\n",
      "val_mask torch.Size([4278]) torch.bool 400\n",
      "test_mask torch.Size([4278]) torch.bool 3478\n"
     ]
    }
   ],
   "source": [
    "for k in ['train_mask','val_mask','test_mask']:\n",
    "    m = data['movie'][k]\n",
    "    print(k, m.shape, m.dtype, m.sum().item())  # count of True = split size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10fcd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Forces actor/director to use learnable embeddings.\n",
    "    Keeps projection for node types with real features (e.g., movie).\n",
    "\"\"\"\n",
    "# Hybrid feature construction\n",
    "hybrid_types = {'actor', 'director'}\n",
    "embeddings = nn.ModuleDict()\n",
    "proj = nn.ModuleDict()\n",
    "\n",
    "for ntype in data.node_types:\n",
    "    x = data[ntype].get('x', None)\n",
    "    if ntype in hybrid_types:\n",
    "        if x is not None:\n",
    "            emb_dim = hidden // 2\n",
    "            proj_dim = hidden - emb_dim\n",
    "            proj[ntype] = nn.Linear(x.size(-1), proj_dim, bias=False)\n",
    "            embeddings[ntype] = nn.Embedding(data[ntype].num_nodes, emb_dim)\n",
    "        else:\n",
    "            embeddings[ntype] = nn.Embedding(data[ntype].num_nodes, hidden)\n",
    "    else:\n",
    "        if x is not None:\n",
    "            proj[ntype] = nn.Linear(x.size(-1), hidden, bias=False)\n",
    "        else:\n",
    "            embeddings[ntype] = nn.Embedding(data[ntype].num_nodes, hidden)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "embeddings = embeddings.to(device)\n",
    "proj = proj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b75ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (director): Embedding(2081, 64)\n",
       "  (actor): Embedding(5257, 64)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33647007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Define HGT model\n",
    "class HGTNet(nn.Module):\n",
    "    def __init__(self, metadata, hidden=64, heads=4, layers=2, out_dim=3):\n",
    "        super().__init__()\n",
    "        self.input_dropout = nn.Dropout(0.2)\n",
    "        self.layers = nn.ModuleList([\n",
    "            HGTConv(in_channels=hidden, # this is from hetregenous graph transformer\n",
    "                    out_channels=hidden,\n",
    "                    metadata=metadata,\n",
    "                    heads=heads)\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.cls = nn.Linear(hidden, out_dim)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        h = {k: self.input_dropout(v) for k, v in x_dict.items()}  # input feature dropout\n",
    "        for conv in self.layers:\n",
    "            h = conv(h, edge_index_dict)  # dict -> dict\n",
    "            h = {k: F.elu(v) for k, v in h.items()}\n",
    "            h = {k: self.dropout(v) for k, v in h.items()}\n",
    "        logits = self.cls(h['movie'])\n",
    "        return logits, h  # return movie logits + all-type embeddings\n",
    "\n",
    "model = HGTNet(metadata, hidden=hidden, heads=4, layers=3, out_dim=int(data['movie'].y.max().item()+1))\n",
    "#opt = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-3)\n",
    "\n",
    "model = model.to(device)\n",
    "for ntype in proj: proj[ntype] = proj[ntype].to(device)\n",
    "for ntype in embeddings: embeddings[ntype] = embeddings[ntype].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ee2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensor storages to device\n",
    "for ntype in data.node_types:\n",
    "    for k, v in data[ntype].items():\n",
    "        data[ntype][k] = v.to(device)\n",
    "for etype in data.edge_types:\n",
    "    data[etype].edge_index = data[etype].edge_index.to(device)\n",
    "\n",
    "y = data['movie'].y\n",
    "train_mask = data['movie'].train_mask\n",
    "val_mask = data['movie'].val_mask\n",
    "test_mask = data['movie'].test_mask\n",
    "\n",
    "def get_xdict():\n",
    "    xd = {}\n",
    "    for ntype in data.node_types:\n",
    "        x = data[ntype].get('x', None)\n",
    "        if (ntype in hybrid_types) and (ntype in proj) and (ntype in embeddings) and (x is not None):\n",
    "            xd[ntype] = torch.cat([proj[ntype](x), embeddings[ntype].weight], dim=-1)\n",
    "        elif ntype in proj and x is not None:\n",
    "            xd[ntype] = proj[ntype](x)\n",
    "        elif ntype in embeddings:\n",
    "            xd[ntype] = embeddings[ntype].weight\n",
    "        else:\n",
    "            raise KeyError(f\"Missing modules for node type: {ntype}\")\n",
    "    return {k: v.to(device) for k, v in xd.items()}\n",
    "\n",
    "\n",
    "def build_x_dict():\n",
    "    # Use the same logic in training to avoid drift\n",
    "    return get_xdict()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_split(split='val'):\n",
    "    model.eval()\n",
    "    xd = get_xdict()\n",
    "    logits, hdict = model(xd, data.edge_index_dict)\n",
    "    if split == 'val':\n",
    "        mask = val_mask\n",
    "    elif split == 'test':\n",
    "        mask = test_mask\n",
    "    else:\n",
    "        mask = train_mask\n",
    "    pred = logits[mask].argmax(dim=-1)\n",
    "    acc = (pred == y[mask]).float().mean().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cecf696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | loss 1.0542 | val acc 0.3925\n",
      "Epoch 020 | loss 0.5942 | val acc 0.5425\n",
      "Epoch 030 | loss 0.3401 | val acc 0.5450\n",
      "Epoch 040 | loss 0.3153 | val acc 0.5375\n",
      "Epoch 050 | loss 0.3067 | val acc 0.5350\n",
      "Epoch 060 | loss 0.3035 | val acc 0.5550\n",
      "Epoch 070 | loss 0.3021 | val acc 0.5475\n",
      "Epoch 080 | loss 0.3001 | val acc 0.5600\n",
      "Epoch 090 | loss 0.3000 | val acc 0.5775\n",
      "Epoch 100 | loss 0.2993 | val acc 0.5800\n",
      "Epoch 110 | loss 0.2994 | val acc 0.5775\n",
      "Epoch 120 | loss 0.2990 | val acc 0.5625\n",
      "Epoch 130 | loss 0.2978 | val acc 0.5625\n",
      "Epoch 140 | loss 0.2984 | val acc 0.5700\n",
      "Epoch 150 | loss 0.2977 | val acc 0.5750\n",
      "Epoch 160 | loss 0.2980 | val acc 0.5650\n",
      "Epoch 170 | loss 0.2975 | val acc 0.5650\n",
      "Epoch 180 | loss 0.2973 | val acc 0.5725\n",
      "Epoch 190 | loss 0.2969 | val acc 0.5675\n",
      "Epoch 200 | loss 0.2974 | val acc 0.5675\n",
      "Epoch 210 | loss 0.2965 | val acc 0.5725\n",
      "Epoch 220 | loss 0.2971 | val acc 0.5700\n",
      "Epoch 230 | loss 0.2969 | val acc 0.5675\n",
      "Epoch 240 | loss 0.2975 | val acc 0.5675\n",
      "Epoch 250 | loss 0.2962 | val acc 0.5675\n",
      "Epoch 260 | loss 0.2963 | val acc 0.5775\n",
      "Epoch 270 | loss 0.2963 | val acc 0.5700\n",
      "Epoch 280 | loss 0.2967 | val acc 0.5750\n",
      "Epoch 290 | loss 0.2966 | val acc 0.5750\n"
     ]
    }
   ],
   "source": [
    "# 4) Train\n",
    "def build_x_dict():\n",
    "    out = {}\n",
    "    for ntype in data.node_types:\n",
    "        if ntype in embeddings:\n",
    "            out[ntype] = embeddings[ntype].weight\n",
    "        else:\n",
    "            out[ntype] = proj[ntype](data[ntype].x)\n",
    "    return out\n",
    "\n",
    "# Make sure optimizer sees these params:\n",
    "proj_params = [p for m in proj.values() for p in m.parameters()]\n",
    "emb_params  = [p for m in embeddings.values() for p in m.parameters()]\n",
    "#opt = torch.optim.AdamW(list(model.parameters()) + proj_params + emb_params, lr=3e-3, weight_decay=1e-4)\n",
    "opt = torch.optim.AdamW(\n",
    "    list(model.parameters())\n",
    "    + [p for m in proj.values() for p in m.parameters()]\n",
    "    + [p for m in embeddings.values() for p in m.parameters()],\n",
    "    lr=3e-3, weight_decay=1e-3\n",
    ")\n",
    "from copy import deepcopy\n",
    "best = dict(val=-1, model=None, proj={}, emb={})\n",
    "best_val, best_state = 0.0, None\n",
    "\n",
    "for epoch in range(1, 300):\n",
    "    model.train()\n",
    "    #x_dict = {k: v.to(device) for k, v in build_x_dict().items()}\n",
    "    #edge_index_dict = {k: v.to(device) for k, v in data.edge_index_dict.items()}\n",
    "    x_dict = get_xdict()\n",
    "    logits, _ = model(x_dict, data.edge_index_dict)\n",
    "    loss = F.cross_entropy(logits[train_mask], data['movie'].y[train_mask].to(device),label_smoothing=0.1)\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        val_acc = eval_split('val')\n",
    "        if val_acc > best['val']:\n",
    "            best['val'] = val_acc\n",
    "            best['model'] = deepcopy(model.state_dict())\n",
    "            best['proj']  = {k: deepcopy(m.state_dict()) for k,m in proj.items()}\n",
    "            best['emb']   = {k: deepcopy(m.state_dict()) for k,m in embeddings.items()}\n",
    "        print(f\"Epoch {epoch:03d} | loss {loss.item():.4f} | val acc {val_acc:.4f}\")\n",
    "\n",
    "model.load_state_dict(best['model'])\n",
    "for k,m in proj.items(): m.load_state_dict(best['proj'][k])\n",
    "for k,m in embeddings.items(): m.load_state_dict(best['emb'][k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7943345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5635\n"
     ]
    }
   ],
   "source": [
    "# 5) Test\n",
    "if best_state:\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "test_acc = eval_split('test')\n",
    "print(f\"Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca244b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie embeddings shape: torch.Size([4278, 128])\n"
     ]
    }
   ],
   "source": [
    "# 6) Get embeddings for downstream tasks (similarity, clustering, etc.)\n",
    "@torch.no_grad()\n",
    "def get_movie_embeddings():\n",
    "    model.eval()\n",
    "    xd = get_xdict()\n",
    "    _, hdict = model(xd, data.edge_index_dict)\n",
    "    return hdict['movie'].cpu()\n",
    "\n",
    "movie_Z = get_movie_embeddings()\n",
    "print(\"Movie embeddings shape:\", movie_Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0066cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('movie', 'to', 'director'), ('movie', 'to', 'actor'), ('director', 'to', 'movie'), ('actor', 'to', 'movie')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecfbf8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2], device='mps:0'), tensor([1135, 1584, 1559], device='mps:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['movie'].x.shape, data['movie'].y.shape\n",
    "data['movie'].y.unique(return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18227a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4278, 3066])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie'].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a85c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie', 'director', 'actor']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ba065da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['actor'].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823ea7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5257, 3066])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['actor'].x.shape #5257 are nodes , 3066 feature vector dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbff85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17004.1543, device='mps:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['actor'].x.abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c258639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "427c0bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5257, 3066]), torch.float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['actor'].x\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1c4d06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0010549816070124507)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value range and a few sample rows\n",
    "x.min().item(), x.max().item(), x.mean().item()\n",
    "#x[0, :20], x[1, :20]  # peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eba2fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 76501, 0.004746319664979977)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['actor'].x\n",
    "is_integer_like = bool((x == x.round()).all())        # counts?\n",
    "nnz = x.count_nonzero().item()\n",
    "density = nnz / x.numel()\n",
    "is_integer_like, nnz, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN)",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
